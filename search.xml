<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[深度学习常见Loss推导]]></title>
    <url>%2Fpost%2F19fc17a4.html</url>
    <content type="text"><![CDATA[1. Softmax Loss 推导 (1) $N$为类别数 (2) $a$为输出向量，$a_j$为向量$a$的第$j$个值 参考：卷积神经网络系列之softmax loss对输入的求导推导 1.1 Softmax S_i=\frac{e^{a_i}}{\sum_{j}e^{a_j}} 1.2 Cross-entropy Loss L=\sum_{j}-y_ilnP_j1.3 Softmax Loss 当Cross-entropy的$P_j=S_i$ ，即Softmax输出的时候。 L_{softmax}=\sum_{j}-y_ilnS_i1.4 Softmax对Softmax输入的导数 $S_i$对$a_j$求导： \frac{\partial{S_i}}{\partial{a_j}}=\frac{\partial{\frac{e^{a_i}}{\sum_ke^{a_k}}}}{\partial a_j} 这里求导有两种情况 1）当$i=j$时： \begin{aligned} \frac{\partial{S_i}}{\partial{a_j}} &=\frac{\partial{S_i}}{\partial{a_i}} \\ &=\frac{\frac{\partial{e^{a_i}}}{\partial{a_i}}\sum_ke^{a_k}-\frac{\sum_ke^{a_k}}{\partial{a_i}}e^{a_i}}{(\sum_ke^{a_k})^2} \\ &=\frac{e^{a_i}\sum_ke^{a_k}-e^{a_i}e^{a_i}}{\sum_k{e^{2a_k}}} \\ &=\frac{e^{a_i}}{\sum_k{e^{a_k}}}-\frac{e^{a_i}}{\sum_k{e^{a_k}}}\cdot{\frac{e^{a_i}}{\sum_k{e^{a_k}}}} \\ &=S_i-S_i^2\\ &=S_i(1-S_i) \end{aligned} 2）当$i≠j$时： \begin{aligned} \frac{\partial{S_i}}{\partial{a_j}} &=\frac{\frac{\partial{e^{a_i}}}{\partial{a_j}}\sum_ke^{a_k}-\frac{\sum_ke^{a_k}}{\partial{a_j}}e^{a_i}}{(\sum_ke^{a_k})^2} \\ &=\frac{-e^{a_j}e^{a_i}}{\sum_k{e^{2a_k}}} \\ &=-S_jS_i \end{aligned} 1.5 Softmax Loss对softmax输入的导数 第③个等号就用到了上面$S_i$对$a_j$求导的结论，第三个等号结果的左半部分是$i=k$的时候$S_i$对$a_j$求导的导数，右半部分是$i≠k$的时候S_i$对​$a_j$求导的导数。 第⑥、⑦个等号是将$y_iS_i​$合并到∑里面。最后一个等号的成立是建立在假设$∑y_k=1​$的前提下，这个对于常见的单标签分类任务而言都是成立的。 \begin{aligned} \frac{\partial{L_{softmax}}}{\partial{a_k}}&=-\sum_ky_k\frac{\partial{lnS_k}}{\partial{a_i}} \\ &=-\sum_ky_k\frac{1}{S_k}\frac{\partial{S_k}}{\partial{a_i}} \\ &=-y_i(1-S_i)-\sum_{k≠i}y_k\frac{1}{S_k}({-S_kS_i}) \\ &=-y_i(1-S_i)+\sum_{k≠i}y_kS_i \\ &=-y_i+y_iS_i+\sum_{k≠i}y_kS_i \\ &=\sum_ky_kS_i-y_i \\ &=S_i-y_i \end{aligned}1.6 总结因此假设一个5分类任务，经过Softmax层后得到的概率向量$S$是$[0.1,0.2,0.25,0.4,0.05]$，真实标签$y$是$[0,0,1,0,0]$，那么损失回传时该层得到的梯度就是$p-y=[0.1,0.2,-0.75,0.4,0.05]$。这个梯度就指导网络在下一次forward的时候更新该层的权重参数。]]></content>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习优化器]]></title>
    <url>%2Fpost%2F1eda57ac.html</url>
    <content type="text"><![CDATA[参考资料：深度学习最全优化方法总结比较（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam） 1. 随机梯度下降 批梯度下降(Gradient Descent) 随机批梯度下降(Stotastic Gradient Descent) 每次梯度计算只使用一个随机样本(可能是噪声样本) 避免在类似的样本上进行冗余计算 增加了跳出当前局部最小值的可能 可以通过减小学习率，来使其能够与GD有相同的收敛速度 小批量随机梯度下降(Mini batch SGD) 每次梯度计算使用小批量的样本 梯度计算比单样本计算更加稳定 便于使用矩阵计算 适当的batch size训练效率高 2. 随机梯度下降的困难 局部梯度的反方向不一定是函数整体的下降方向。 学习率衰减法，难以根据数据进行自适应。 对不同的参数采取不同的学习率(数据稀疏，不平衡)。 容易困在局部最小点，甚至是鞍点。 3. 动量方法(Momentum) 目的: 解决随机梯度的局部梯度的反方向不一定是函数整体的下降方向问题。 方法： 动量法：(Momentum)（适用于隧道型曲面） 方法： 每次更新都吸收上一次更新的余势。使得主体方向得到了更好的保留，使得效果被不断的放大。 v_t = \gamma v_{t-1}+\eta\nabla_{\theta}J(\theta) \\ \theta_t=\theta_{t-1}-v_t 缺点： 在前期下降比较快，收敛速度较好，但到最优值附近时容易由于动量过大而导致优化过度。 改进动量法：(Nesterov) 方法：利用主体的下降方向，预判下一步优化的位置，根据预判的位置计算优化的梯度。 v_t = \gamma v_{t-1} + \eta \nabla_{\theta}J(\theta-\gamma v_{t-1}) \\ \theta=\theta-v_tmomentum首先计算一个梯度(短的蓝色向量)，然后在加速更新梯度的方向进行一个大的跳跃(长的蓝色向量)，nesterov项首先在之前加速的梯度方向进行一个大的跳跃(棕色向量)，计算梯度然后进行校正(绿色梯向量) 4. 自适应梯度方法(Ada) 目的： 解决学习率衰减法，难以根据数据进行自适应的问题。 更新频繁的参数使用较小的学习率。 更新较少的参数使用较大的学习率。 方法： Adagrad方法： 思路：Adagrad对每个参数的历史梯度更新进行叠加，并以此作为下一次更新的惩罚系数。（约束学习率） 算法： 梯度：$g_{t,i}=\nabla_{\theta}J(\theta_i)$ 梯度历史矩阵: $G_t$是对角阵，其中$G_{t,ii}=\sum_{k}g_{k,i}^2$ 参数更新：（历史梯度大，则$\eta$项越小） \theta_{t+1,i}=\theta_{t,i}-\frac{\eta}{\sqrt{G_{t,ii}+\epsilon}}\cdot g_{t, i} 存在的问题： 随着训练的进行，学习率衰减过快。 梯度与参数单位不匹配 RMSprop（Adadelta方法第一版）： 目的：解决随着训练的进行，学习率衰减过快。 思路：使用梯度平方的移动平均来取代全部的历史平方和。 算法： 梯度：$g_{t,i}=\nabla_{\theta}J(\theta_i)$ 移动平均: $\mathbb{E}_{t}[g^2]=\gamma \mathbb{E}_{t-1}[g^2] + (1-\gamma) g_{t}^2$ 参数更新：（更新系数分母换了） \theta_{t+1, i} = \theta_{t,i} - \frac{\eta}{\sqrt{\mathbb{E}_{t,ii}+\epsilon}} \cdot g_{t,i} 特点： 其实RMSprop依然依赖于全局学习率 RMSprop算是Adagrad的一种发展，和Adadelta的变体，效果趋于二者之间 适合处理非平稳目标 对于RNN效果很好 Adadelta方法第二版: 目的：梯度与参数单位不匹配 思路：使用参数更新的移动平均来取代学习率$\eta$ 算法： 参数更新: （学习率换成参数的移动平均自适应） \theta_{t+1, i} = \theta_{t,i} - \frac{\sqrt{\mathbb{E}_{t-1}[\Delta \theta]}}{\sqrt{\mathbb{E}_{t,ii}+\epsilon}} \cdot g_{t,i} 特点： 训练初中期，加速效果不错，很快 训练后期，反复在局部最小值附近抖动 5. 动量+自适应方法(Adam) Adam （带动量项的RMSprop） 思路：在Adadelta的梯度平方和(二阶矩)的基础上引入动量方法的的一阶矩(梯度) 算法： 一阶矩(动量)： $m_t=\beta_1 m_{t-1}+(1-\beta_1)g_t$ （保持下降速度） 二阶矩(Adadelta)：$v_t=\beta_2 v_{t-1}+(1-\beta_2)g_t^2$ （保持参数自适应） 参数更新： \theta_{t+1}=\theta_{t} - \frac{\eta}{\sqrt{v_{t}}+\epsilon}m_t 特点： 经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。 适用于大数据集和高维空间 NAdam (引入Nesterov) 对学习率有了更强的约束 6. 小结 对于稀疏数据，尽量使用学习率可自适应的优化方法，不用手动调节，而且最好采用默认值 SGD通常训练时间更长，容易陷入鞍点，但是在好的初始化和学习率调度方案的情况下，结果更可靠 如果在意更快的收敛，并且需要训练较深较复杂的网络时，推荐使用学习率自适应的优化方法。 Adadelta，RMSprop，Adam是比较相近的算法，在相似的情况下表现差不多。 在想使用带动量的RMSprop，或者Adam的地方，大多可以使用Nadam取得更好的效果 鞍点：]]></content>
      <tags>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[刷题-搜索]]></title>
    <url>%2Fpost%2Fd42edc1.html</url>
    <content type="text"><![CDATA[1. [Leetcode 200] 岛屿的个数 解法： DFS：一次遍历，遇到1则进行深搜，遍历过的1设为2，遇到非1或者越界则深搜停止，统计深搜的次数，即为岛屿数量。(这里采用) BFS: 循环遍历每个点，如果该点是0，则跳过，如果是1，岛屿数目加1，并加入队列，并将该点改为0，避免重复访问，然后进行广搜，取出队首元素，搜索该点周围四个点，如果有1就加入队列，并将1改为0，否则就跳过，当队列空时，一块岛屿搜索完毕，进入下一块搜索。(代码可参考：岛屿的个数 BFS) 并查集: 将二维数组重新编号，从0开始，从左到右，从上到下，直到n*m-1（其中n为行数，m为列数），对于位置(i,j)则编号为i*m+j，那么相邻（左右，上下）的为同一个值，则认为他们相通。那么最终只要统计一下father[i]==i且对应值为1的个数即可。(代码可参考: 岛屿的个数 Disjoint Set) 代码： 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int numIslands(vector&lt;vector&lt;char&gt;&gt;&amp; grid) &#123; if(grid.empty()) return 0; int res = 0; for(int i = 0; i &lt; grid.size(); i++)&#123; for(int j = 0; j &lt; grid[0].size(); j++)&#123; if(grid[i][j] == '1')&#123; dfs(grid, i, j); res++; &#125; &#125; &#125; return res; &#125; void dfs(vector&lt;vector&lt;char&gt;&gt;&amp; grid, int row, int col)&#123; if(row &lt; 0 || col &lt; 0 || row &gt;= grid.size() || col &gt;= grid[0].size() || grid[row][col] == '0' || grid[row][col] == '2') return; if(grid[row][col] == '1') grid[row][col] = '2'; dfs(grid, row-1, col); dfs(grid, row+1, col); dfs(grid, row, col-1); dfs(grid, row, col+1); &#125; &#125;;]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[刷题]链表专题]]></title>
    <url>%2Fpost%2F6db30a46.html</url>
    <content type="text"><![CDATA[[Leetcode 141, 142] 环形链表，环形链表 II （剑指Offer面试题23） 解法：(链表遍历，快慢指针) 判环：快慢指针，快指针+2， 慢指针+1，若快指针在到达链表尾(不带环的才有链表尾)之前与慢指针相遇，则有环。 找入口：快慢指针第一次相遇节点与头结点之间的节点数与环中节点数相同，两个指针一个从链表头开始，一个从相遇节点开始遍历，两个指针再次相遇节点为入口节点。 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: // 找入口 ListNode *detectCycle(ListNode *head) &#123; if(!JudgeCycle(head)) return nullptr; ListNode *pFirstptr = head; //第一次相遇节点位置就是环内节点数 while(pFirstptr != pMeetNode)&#123; pFirstptr = pFirstptr -&gt; next; pMeetNode = pMeetNode -&gt; next; &#125; return pFirstptr; &#125; // 判环 bool JudgeCycle(ListNode *head)&#123; if(head == nullptr) return false; ListNode *pFastptr = head; ListNode *pSlowptr = head; while(pFastptr -&gt; next &amp;&amp; pFastptr -&gt; next -&gt; next)&#123; pFastptr = pFastptr -&gt; next -&gt; next; pSlowptr = pSlowptr -&gt; next; if(pFastptr == pSlowptr)&#123; pMeetNode = pFastptr; return true; &#125; &#125; return false; &#125;private: ListNode *pMeetNode;&#125;; [Leetcode 206] 反转链表 (剑指Offer面试题24) 解法： 代码： 12345678910111213141516171819202122232425262728/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if(head == nullptr) return nullptr; // 注意空节点 if(head-&gt;next == nullptr) return head; // 注意只有一个节点 ListNode* pPrePtr = head; ListNode* pTransPtr = head -&gt;next; pPrePtr-&gt; next = nullptr; // 注意头结点处理 while(pTransPtr-&gt;next != nullptr)&#123; ListNode* pTmpPtr = pTransPtr -&gt; next; pTransPtr-&gt;next = pPrePtr; pPrePtr = pTransPtr; pTransPtr = pTmpPtr; &#125; pTransPtr -&gt; next = pPrePtr; // 注意尾节点处理 return pTransPtr; &#125;&#125;; [Leetcode 21] 合并两个有序链表 (剑指Offer面试题 25) 解法： 优先队列重排 (可参考 提交记录99%代码) 比较插入列表 （这里使用） 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) &#123; if(l1 == nullptr &amp;&amp; l2 == nullptr) return nullptr; if(l1 == nullptr &amp;&amp; l2 != nullptr) return l2; if(l2 == nullptr &amp;&amp; l1 != nullptr) return l1; ListNode* res; ListNode* pMergeNode; if(l1-&gt;val &lt; l2-&gt;val)&#123; pMergeNode = l1; l1 = l1-&gt;next; &#125; else&#123; pMergeNode = l2; l2 = l2-&gt;next; &#125; res = pMergeNode; while(true)&#123; if(l1 == nullptr &amp;&amp; l2 != nullptr)&#123; pMergeNode-&gt;next = l2; break; &#125; if(l2 == nullptr &amp;&amp; l1 != nullptr)&#123; pMergeNode-&gt;next = l1; break; &#125; if(l1 == nullptr &amp;&amp; l2 == nullptr)&#123; break; &#125; if(l1-&gt;val &lt; l2-&gt;val)&#123; pMergeNode-&gt;next = l1; l1 = l1-&gt;next; &#125;else&#123; pMergeNode-&gt;next = l2; l2 = l2-&gt;next; &#125; pMergeNode = pMergeNode-&gt;next; &#125; return res; &#125;&#125;; [Leetcode23] 合并K个排序链表 解法： 优先队列或列表遍历插入，优先队列效率相对高一些，这里列出的是列表遍历比较插入的代码，优先队列可参考提交记录99%代码。 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; ListNode* res; ListNode* pMerge = new ListNode(0); res = pMerge; while(!isAllNodeEnd(lists))&#123; int tmp = INT_MAX; int index = 0; for(int i = 0; i &lt; lists.size() ; i++)&#123; if(lists[i] != nullptr)&#123; if(lists[i]-&gt;val &lt; tmp)&#123; tmp = lists[i]-&gt;val; index = i; &#125; &#125; &#125; pMerge-&gt;next = lists[index]; pMerge = pMerge-&gt;next; lists[index] = lists[index]-&gt;next; &#125; return res-&gt;next; &#125; bool isAllNodeEnd(vector&lt;ListNode*&gt;&amp; lists)&#123; for(auto item : lists)&#123; if(item != nullptr) return false; &#125; return true; &#125;&#125;;]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[刷题]递归回溯专题]]></title>
    <url>%2Fpost%2F8cb158ac.html</url>
    <content type="text"><![CDATA[1. [剑指Offer 面试题17] 打印从1到最大的n位数 题目：输入数字n，按顺序打印出从1到最大的n位十进制数。比如输入3， 打印出1,2，…，999。 解法： 全排列解，这里主要用这个方式，有需要在输出时，对高位0进行截断。 大数加法解 代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243class Overview17&#123;public: Overview17()&#123;&#125; ~Overview17()&#123;&#125; void PrintAllNumber(int n)&#123; vector&lt;int&gt; curr; // 递归当前数字 vector&lt;vector&lt;int&gt;&gt; res; //全部数字列表 dfs(res, 0, n, curr); // 打印数字 for (auto item : res)&#123; for (auto it : item) &#123; cout &lt;&lt; it; &#125; cout &lt;&lt; endl; &#125; &#125; void dfs(vector&lt;vector&lt;int&gt;&gt; &amp; res, int depth, int n, vector&lt;int&gt; curr)&#123; if (depth &gt;= n)&#123; res.emplace_back(curr); return; &#125; for (int i = 0; i &lt; 10; i++)&#123; curr.emplace_back(i); dfs(res, depth + 1, n, curr); curr.pop_back(); &#125; &#125;&#125;;int main()&#123; Overview17 ocs; ocs.PrintAllNumber(2); return 0;&#125; 2. [Leetcode 46] 全排列 解法：递归，注意去重 代码： 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; if (nums.size() == 0) return&#123;&#125;; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; curr_vec; vector&lt;bool&gt; used; for (int i = 0; i &lt; nums.size(); i++) &#123; used.push_back(false); &#125; dfs(res, nums, 0, curr_vec, used); return res; &#125; void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; res, vector&lt;int&gt;&amp; nums, int depth, vector&lt;int&gt; curr_vec, vector&lt;bool&gt; used) &#123; if (depth &gt;= nums.size()) &#123; res.emplace_back(curr_vec); return; &#125; for (int i = 0; i &lt; nums.size(); i++) &#123; if (used[i]) continue; used[i] = true; curr_vec.emplace_back(nums[i]); dfs(res, nums, depth + 1, curr_vec, used); curr_vec.pop_back(); used[i] = false; &#125; &#125;&#125;; 3. [Leetcode 47] 全排列 II 解法: 递归，有可重复数字，不要递归重了。对数列进行排序，让相同的数字连在一起，如果当前位已经使用过，或者该位的前一位与该位相同并且前一位没有被使用过，这时两个排列会相同，因而略过。 代码: 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; if (nums.size() &lt;= 0) return&#123;&#125;; sort(nums.begin(), nums.end()); vector&lt;vector&lt;int&gt;&gt; res; vector&lt;bool&gt; used; vector&lt;int&gt; curr; for (auto item : nums) &#123; used.push_back(false); &#125; dfs(res, nums, curr, used, 0); return res; &#125; void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; res, vector&lt;int&gt;&amp; nums, vector&lt;int&gt; curr, vector&lt;bool&gt; used, int depth) &#123; if (depth &gt;= nums.size()) &#123; res.emplace_back(curr); return; &#125; for (int i = 0; i &lt; nums.size(); i++) &#123; if (used[i]) continue; if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i-1]) continue; used[i] = true; curr.emplace_back(nums[i]); dfs(res, nums, curr, used, depth + 1); curr.pop_back(); used[i] = false; &#125; &#125;&#125;;]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[刷题-栈和队列]]></title>
    <url>%2Fpost%2Fdb3d6a7.html</url>
    <content type="text"><![CDATA[[Leetcode 232] 用栈实现队列 （剑指OFFER面试题 9） 解法：一个栈(push栈)用于接收push，一个栈(pop栈)用于top(peek)和pop 当pop栈为空，且push栈不为空时，将push栈的元素转移到pop栈中 当pop栈不为空时，将pop栈的数据pop出去 push操作只在push栈进行 注意： leetcode上可以不进行异常处理，能a过，但是面试时候最好还是加上空栈的异常处理。 泛型支持。 线程安全。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class MyQueue &#123;private: stack&lt;int&gt; spush; stack&lt;int&gt; spop;public: /** Initialize your data structure here. */ MyQueue() &#123; &#125; /** Push element x to the back of queue. */ void push(int x) &#123; spush.push(x); &#125; /** Removes the element from in front of queue and returns that element. */ int pop() &#123; if (spop.empty())&#123; while (!spush.empty()) &#123; spop.push(spush.top()); spush.pop(); &#125; &#125; int res = spop.top(); spop.pop(); return res; &#125; /** Get the front element. */ int peek() &#123; if (spop.empty())&#123; while (!spush.empty()) &#123; spop.push(spush.top()); spush.pop(); &#125; &#125; return spop.top(); &#125; /** Returns whether the queue is empty. */ bool empty() &#123; return spush.empty()&amp;&amp;spop.empty(); &#125;&#125;;]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[刷题]二叉树专题]]></title>
    <url>%2Fpost%2F76e180f5.html</url>
    <content type="text"><![CDATA[1. [Leetcode 105] 从前序与中序遍历序列构造二叉树 (剑指OFFER面试题 7) 解法：递归，由先序序列确定子树根节点，由中序序列确定当前节点下的子树范围。 主要参数(递归函数)：先序序列的起点idx与终点idx， 中序序列的起点idx与终点idx。 递归停止条件： 先序序列或中序序列的起点idx &gt; 终点idx。 递归参数更新方法： 左子树更新: 先序起点idx+1。 preL + 1 先序终点为中序确定左子树节点数量num + 先序起点idx。 preL + num 中序起点为之前递归层中的中序起点。 inL 中序终点为根节点在中序序列中的idx - 1。 inRoot - 1 右子树更新: 先序起点idx+1 + 中序确定左子树节点数量num。 preL + num + 1 先序终点为之前递归层中的先序终点。 preR 中序起点为根节点在中序序列中的idx + 1。 inRoot + 1 中序终点为为之前递归层中的中序终点。 inR 12345678910111213141516171819202122232425262728293031323334353637383940/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) &#123; if(preorder.empty()|| inorder.empty()) return nullptr; return TreeIterate(0, preorder.size() - 1, 0, inorder.size() - 1, preorder, inorder); &#125; TreeNode* TreeIterate(int preL, int preR, int inL, int inR, const vector&lt;int&gt;&amp; preorder, const vector&lt;int&gt;&amp; inorder)&#123; if(preL &gt; preR || inL &gt; inR) return nullptr; int inRoot = 0; //中序遍历根节点位置 for(int i = 0; i &lt; inorder.size(); i++) &#123; if(preorder[preL] == inorder[i])&#123; inRoot = i; break; &#125; &#125; int num = inRoot - inL; //中序确定左子树节点数量 TreeNode* currNode = new TreeNode(preorder[preL]); currNode -&gt; left = TreeIterate(preL + 1, preL + num, inL, inRoot - 1 , preorder, inorder); currNode -&gt; right = TreeIterate(preL + num + 1, preR, inRoot + 1, inR, preorder, inorder); return currNode; &#125;&#125;; 2. [Leetcode 572] 另一个树的子树 (剑指Offer面试题 26) 解法：递归寻根相同，根相同后判断子树是否相同。 注意：停止条件，空指针处理 代码： 1234567891011121314151617181920class Solution &#123;public: bool isSame(struct TreeNode* s, struct TreeNode* t) &#123; if(!s &amp;&amp; !t) // 两个子树叶子都是空 return true; if(!s || !t) // 有一个不是空 return false; if(s-&gt;val != t-&gt;val) return false; return isSame(s-&gt;left,t-&gt;left) &amp;&amp; isSame(s-&gt;right,t-&gt;right); &#125; bool isSubtree(struct TreeNode* s, struct TreeNode* t) &#123; if(!s) // 主树为空 return false; if((s-&gt;val == t-&gt;val) &amp;&amp; isSame(s,t)) return true; return isSubtree(s-&gt;left,t) || isSubtree(s-&gt;right,t); &#125;&#125;; 3. [LeetCode 144] 二叉树的前序遍历 解法： 递归，先输出再递归 循环，用栈模拟，节点右子节点入栈，左节点直接输出。 代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; *//////====递归解class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; if(root == nullptr) return &#123;&#125;; Recurrence(res, root); return res; &#125; void Recurrence(vector&lt;int&gt; &amp;res, TreeNode* root)&#123; if(root == nullptr) return; res.emplace_back(root-&gt;val); Recurence(res, root-&gt;left); Recurence(res, root-&gt;right); &#125;&#125;;////====循环解class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; if(root == nullptr) return &#123;&#125;; stack&lt;TreeNode* &gt; transStack; TreeNode* currNode = root; while(true)&#123; res.emplace_back(currNode-&gt;val); if(currNode-&gt;right)&#123; transStack.push(currNode-&gt;right); &#125; if(currNode-&gt;left)&#123; currNode = currNode-&gt;left; &#125;else&#123; if(!transStack.empty())&#123; currNode = transStack.top(); transStack.pop(); &#125;else&#123; currNode = nullptr; &#125; &#125; if(currNode == nullptr) break; &#125; return res; &#125;&#125;; 4. [LeetCode 94] 二叉树的中序遍历 解法： 递归：遍历左节点后输出值 循环： 代码： 12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; if(root == nullptr) return &#123;&#125;; Recurrence(res, root); return res; &#125; void Recurrence(vector&lt;int&gt;&amp; res, TreeNode* root)&#123; if(root == nullptr)&#123; return; &#125; Recurrence(res, root-&gt;left); res.emplace_back(root-&gt;val); Recurrence(res, root-&gt;right); &#125;&#125;;]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[干货收集]]></title>
    <url>%2Fpost%2Fb8a74939.html</url>
    <content type="text"><![CDATA[2017~2019年度我在Github上面收藏的一些优质干货Repo其中有一些很荣幸作为Repo的贡献者，在issue中也结识了不少好友，共同学习 计算机软件工程类 免费的计算机编程类中文书籍 (44638 star) 设计模式-包教不包会 IntelliJ IDEA 简体中文专题教程 成为专业程序员路上用到的各种优秀资料、神器及框架 scala、spark使用过程中，各种测试用例以及相关资料整理 刷题类 Leetcode刷题(正在完善，可贡献) algorithm 深度学习类 deeplearningbook-chinese 随着整理，持续更新]]></content>
      <tags>
        <tag>干货分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[强化学习笔记专题(二)]Nature DQN]]></title>
    <url>%2Fpost%2F22518.html</url>
    <content type="text"><![CDATA[DQN (Nature) 一、 算法流程： 定义可配置参数 episode 数量 M 最大仿真时间 T，$\epsilon-greedy$参数$\epsilon_{low}$,$\epsilon_{high}$ batch size $N​$ 折扣率 $\gamma$，学习率 $\alpha$等优化器参数 Soft update 频率 $C​$ 初始化 初始化 replay buffer 大小N 初始化 Q 网络 $Q​$ ，使用随机权值 $\theta​$ 初始化 TargetQ 网络 $\hat{Q}$ 权值 $\theta^-$，使用 Q 网络的权值 $\theta$ DQN 一个Episode的流程 使用 $\epsilon-greedy$ 策略 选择一个 action $a_t$ 执行当前 action $a_t$， 获取下一个状态 $s_{t+1}$ 和 reward $r_{t}$ 将当前状态$s_t$赋值为下一个状态 $s_{t+1}$ 将五元组$\langle s_t,a_t,r_t,s_{t+1},done \rangle $存入 replay buffer $D$ 训练Q网络$Q​$: [Pre-condition]训练网络的前提是 replay buffer 的已有五元组数量大于 batch size $N$ 从 replay buffer $D​$中随机选取 batch size $N​$条数据$\langle s_j,a_j,r_j,s_{j+1},done\rangle​$ $D_{selected}​$ 计算目标Q值$y​$， $y​$是一个向量，$\{y_j \in y |j\in[0,N]\} ​$，大小为 batch size $N​$ 当 $D_{selected}​$[j] 中 $done=True​$ 时，即终局状态，此时 $y_j=r_j​$ 当 $D_{selected}$[j] 中 $done=False$ 时，即非终局状态，此时$y_i=r_j+\gamma max_{a’}\hat{Q}(s_{j+1},a’;\theta^-)$， 注意这里是用的 TargetQ 网络进行的 使用优化器进行梯度下降，损失函数是(一个batch里面) $(y-Q(s,a;\theta))^2​$，注意这里使用的是Q网络进行，来让计算出来的目标Q值与当前Q网络输出的Q值进行MSE 每 $C$ 次 episode，soft update 一次 target net 参数，$\theta^- = \theta$ 不断迭代Episode流程$M$次 二、对应代码完整代码地址： Nature DQN 初始化 初始化 replay buffer 大小N 初始化 Q 网络 $Q$ ，使用随机权值$\theta$ 初始化 TargetQ 网络 $\hat{Q}$ 权值 $\theta^-$，使用 Q 网络的权值 $\theta$ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 def create_Q_network(self): """ Q net 网络定义 :return: """ # 输入状态 placeholder self.state_input = tf.placeholder("float", [None, self.state_dim]) # Q 网络结构 两层全连接 with tf.variable_scope('current_net'): W1 = self.weight_variable([self.state_dim, 100]) b1 = self.bias_variable([100]) W2 = self.weight_variable([100, self.action_dim]) b2 = self.bias_variable([self.action_dim]) h_layer = tf.nn.relu(tf.matmul(self.state_input, W1) + b1) # Q Value self.Q_value = tf.matmul(h_layer, W2) + b2 # Target Net 结构与 Q相同，可以用tf的reuse实现 with tf.variable_scope('target_net'): W1t = self.weight_variable([self.state_dim, 100]) b1t = self.bias_variable([100]) W2t = self.weight_variable([100, self.action_dim]) b2t = self.bias_variable([self.action_dim]) h_layer_t = tf.nn.relu(tf.matmul(self.state_input, W1t) + b1t) # target Q Value self.target_Q_value = tf.matmul(h_layer_t, W2t) + b2t t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='target_net') e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='current_net') # soft update 更新 target net with tf.variable_scope('soft_replacement'): self.target_replace_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]#===============================================================# def weight_variable(self, shape): """ 初始化网络权值(随机, truncated_normal) :param shape: :return: """ initial = tf.truncated_normal(shape) return tf.Variable(initial)#===============================================================# def bias_variable(self, shape): """ 初始化bias(const) :param shape: :return: """ initial = tf.constant(0.01, shape=shape) return tf.Variable(initial) $\epsilon-greedy$ 策略 定义，这里对$\epsilon$进行一个随时间步的迁移而减小的策略，使其动作选择的不确定性逐渐减小。 123456789101112131415def egreedy_action(self, state): """ epsilon-greedy策略 :param state: :return: """ Q_value = self.Q_value.eval(feed_dict=&#123; self.state_input: [state] &#125;)[0] if random.random() &lt;= self.epsilon: self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / 10000 return random.randint(0, self.action_dim - 1) else: self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / 10000 return np.argmax(Q_value) Replay buffer的定义 1234567891011121314151617181920212223242526def perceive(self, state, action, reward, next_state, done): """ Replay buffer :param state: :param action: :param reward: :param next_state: :param done: :return: """ # 对action 进行one-hot存储，方便网络进行处理 # [0,0,0,0,1,0,0,0,0] action=5 one_hot_action = np.zeros(self.action_dim) one_hot_action[action] = 1 # 存入replay_buffer # self.replay_buffer = deque() self.replay_buffer.append((state, one_hot_action, reward, next_state, done)) # 溢出出队 if len(self.replay_buffer) &gt; REPLAY_SIZE: self.replay_buffer.popleft() # 可进行训练条件 if len(self.replay_buffer) &gt; BATCH_SIZE: self.train_Q_network() Q网络训练 12345678910111213141516171819202122232425262728def train_Q_network(self): """ Q网络训练 :return: """ self.time_step += 1 # 从 replay buffer D中随机选取 batch size N条数据&lt;s_j,a_j,r_j,s_j+1,done&gt; D_selected minibatch = random.sample(self.replay_buffer, BATCH_SIZE) state_batch = [data[0] for data in minibatch] action_batch = [data[1] for data in minibatch] reward_batch = [data[2] for data in minibatch] next_state_batch = [data[3] for data in minibatch] # 计算目标Q值y y_batch = [] Q_value_batch = self.target_Q_value.eval(feed_dict=&#123;self.state_input: next_state_batch&#125;) for i in range(0, BATCH_SIZE): done = minibatch[i][4] if done: y_batch.append(reward_batch[i]) else: y_batch.append(reward_batch[i] + GAMMA * np.max(Q_value_batch[i])) self.optimizer.run(feed_dict=&#123; self.y_input: y_batch, self.action_input: action_batch, self.state_input: state_batch &#125;) Soft update 123def update_target_q_network(self, episode): # 更新 target Q netowrk if episode % REPLACE_TARGET_FREQ == 0: 三、实验结果环境 cart-pole-v0 (期望回报是200) 四、DQN参考论文流程： 五、Double DQNDQN存在的问题是Q function容易过拟合，根据状态 $s_{t+1}$ 选择动作 $a_{t+1}$ 的过程,以及估计 $Q(s_{t+1},a_{t+1})​$ 使用的同一个Q net网络参数，这可能导致选择过高的估计值，从而导致过于乐观的值估计。为了避免这种情况的出现，可以对选择和衡量进行解耦，从而就有了使用 Double DQN 来解决这一问题。 Double DQN与DQN的区别仅在于$y$的求解方式不同，Double DQN根据Q网络参数来选择动作$a_{t+1}$,再用Target Q网络参数来衡量$Q(s_{t+1},a_{t+1})$的值。 Y_t^{DQN}=R_{t+1}+\gamma \hat{Q}(S_{t+1},argmax_a\hat{Q}(S_{t+1},a;\theta_t^-);\theta_t^-)\\ Y_t^{DDQN}=R_{t+1}+\gamma \hat{Q}(S_{t+1},argmax_aQ(S_{t+1},a;\theta_t);\theta_t^-)反映在代码上，就是训练的时候选择Q的时候有点变动： 123456789101112131415161718192021222324252627282930313233343536def train_Q_network(self): """ Q网络训练 :return: """ self.time_step += 1 # 从 replay buffer D中随机选取 batch size N条数据&lt;s_j,a_j,r_j,s_j+1,done&gt;$ D_selected minibatch = random.sample(self.replay_buffer, BATCH_SIZE) state_batch = [data[0] for data in minibatch] action_batch = [data[1] for data in minibatch] reward_batch = [data[2] for data in minibatch] next_state_batch = [data[3] for data in minibatch] # 计算目标Q值y y_batch = [] QTarget_value_batch = self.target_Q_value.eval(feed_dict=&#123;self.state_input: next_state_batch&#125;) Q_value_batch = self.Q_value.eval(feed_dict=&#123;self.state_input: next_state_batch&#125;) for i in range(0, BATCH_SIZE): done = minibatch[i][4] if done: y_batch.append(reward_batch[i]) else: #################用target Q(Q)####################### if DOUBLE_DQN: selected_q_next = QTarget_value_batch[i][np.argmax(Q_value_batch[i])] #################用target Q(target Q)################ else: selected_q_next = np.max(QTarget_value_batch[i]) y_batch.append(reward_batch[i] + GAMMA * selected_q_next) self.optimizer.run(feed_dict=&#123; self.y_input: y_batch, self.action_input: action_batch, self.state_input: state_batch &#125;) 六、DQN，DDQN实验结果对比可以看到DoubleDQN的表现比 DQN稳定 七、 Dueling DDQN八、 Dueling DQN, DDQN, DQN对比]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[强化学习论文] (HDQN) Integrating Temporal Abstraction and Intrinsic Motivation]]></title>
    <url>%2Fpost%2F10845.html</url>
    <content type="text"><![CDATA[论文 题目: Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation 作者: Tejas D. Kulkarni, Karthik R. Narasimhan, Ardavan Saeedi, Joshua B. Tenenbaum 论文: https://arxiv.org/abs/1604.06057 年份: 2016 参考: https://github.com/aleju/papers/blob/master/neural-nets/Hierarchical_Deep_Reinforcement_Learning.md 总结1.主要贡献 提出了一种分层强化学习方法 该方法使用了长期目标(long-term goal)指导短期动作(short-term choice)的选择 2.主要方法 两个重要组件 Meta-controller 负责生成长期目标long term goal; 通过训练Meta-controller使其能够根据当前state来选取目标goal，使得extrinsic reward最大; 当且仅当底层执行器Controller完成一个episode或者达成某个Meta-controller产生的goal的时候，Meta-controller再去产生新的目标goal。 Controller 从环境中获取当前state，并从Meta-controller中获取当前目标goal; 基于当前goal和当前的state，来选取最大化intrinsic reward期望的action，这里与传统的rf相同只是增加了目标goal，这里通过估计action-value function ( $Q_1(s_t, a_t;\theta_1,g_t)$ )来做; Reward 是 intrinsic的，在agent内部，这个intrinsic reward由Critic网络产生，当且仅当当前的目标达到时，才会产生intrinsic reward。 在蒙特祖玛的复仇(Montezuma’s Revenge)上实验 目标Goal是一些手动设置的特定游戏object，比如钥匙，在实验中，将设置一个与游戏屏幕大小相等的遮罩层，当且仅当目标object的位置上的二进制位是1，其他像素上的二进制值为0； Meta-controller通过Q function选择要到达的下一个Goal; Controller根据Q function选择能够到达Goal的action, 其不断迭代选择action，直到其完成一个episode或到达Goal； 每当达到目标Goal时，Critic都会向Controller提供内在奖励(intrinsic reward); CNN用于Meta-controller和Controller，在架构上类似于Atari-DQN论文(shallow CNNs); 使用两个Replay buffer，一个用于Meta-controller(大小为40k)，一个用于Controller(大小为1M); Meta-controller和Controller两者都遵循epsilon-greedy。Epsilon从1.0开始，减小至0.1; 折扣因子γ为0.9; 使用SGD优化。]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强化学习专题笔记(一) 强化学习基础]]></title>
    <url>%2Fpost%2F17172.html</url>
    <content type="text"><![CDATA[一、长期回报对于问题的简化，采用理想的MDP，简化问题到具有马尔科夫性，对于马尔科夫决策过程而言，在理想状态下，每一个行动都要为最终的目标最大化长期回报 而努力。 \max\sum_{t}{r_t}但是很多情况下，仿真的时间维度较大，步数较多，甚至可以无限循环下去，这样的情况下我们需要引入一个可以和收敛的无穷数列，来替代我们最原始的长期回报公式。即对未来的回报乘以一个折扣率，使得长期回报变得更有意义： \sum_{t=0}{\gamma^tr_t} （\gamma < 1）由此我们引出长期回报的概念，即从当前状态开始对之后的所有回报，运用上式进行累加的折扣率计算： Ret_t=\sum_{k=0}\gamma^kr_{t+k+1}但是长期回报需要知道未来的行动情况，我们需要对上式进行一个合理的估计，因而我们定义了策略的价值。 二、值函数由于环境的原因，MDP中的状态转移概率有时候并不能够确定，因而需要基于状态转移来估计长期回报的期望。τ是从某个状态s出发，根据策略与状态转移概率采样得到的序列(trajectory)。那么价值函数可以表示为： v_{\pi}{(s_t)} = \mathbb{E}_{s,a\simτ}[\sum_{k=0}\gamma^kr_{t+k+1}] =\sum_{\tau}{p(\tau)}{\sum_{k=0}^{\infin}{\gamma^k}{r_{t+k+1}}}根据MDP模型的形式，值函数一般分为两种： 状态值函数 $v_{\pi}{(s)}​$: 已知当前状态s，按照某种策略行动产生的长期回报期望； 状态-动作值函数 $q_{\pi}{(s,a)}​$: 已知当前状态s及动作a，按照某种策略行动产生的长期回报期望。 由于符合马尔科夫性，我们可以将值函数的形式进行马尔科夫展开,其中${\pi(a_t|s_t)}$表示，在$s_t$状态下选择策略$\pi$的概率，策略$\pi$将产生行动$a_t$，$p(s_{t+1}|s_t,a_t)$表示在策略$\pi$的情况下，从$s_t，a_t$到达$s_{t+1}$的概率。 v_{\pi}{(s_t)}=\sum_{(s_t,a_t,...)\sim\tau]}{\pi(a_t|s_t)}p(s_{t+1}|s_t,a_t)...{\sum_{k=0}^{\infin}{\gamma^k}{r_{t+k+1}}}三、贝尔曼方程 状态值函数的贝尔曼方程 通过代换消元，可以将上式整理为状态值函数的贝尔曼方程： v_{\pi}(s_t)=\sum_{a_t}\pi(a_t|s_t)\sum_{s_{t+1}}{p(s_{t+1}|s_t,a_t)[r_{t+1}+\gamma v_{\pi}(s_{t+1})]}更直观一点可以将贝尔曼方程描述为一种DP的形式，即当前状态$s$下，选择策略$\pi$的长期回报期望。 v_{\pi}(s_t)=\sum_{a_t,s_t+1}\pi{(a_t|s_t)}\mathbb{E}[r_{t+1} + \gamma v_{\pi}(s_{t+1})] 状态-动作值函数的贝尔曼方程 类似地，可以定义状态-动作值函数的贝尔曼方程： q_{\pi}(s_t,a_t)=\sum_{s_{t+1}}p(s_{t+1}|s_t,a_t)\sum_{a_{t+1}}p(a_{t+1}|s_{t+1})[r_{t+1}+\gamma q_\pi{(s_{t+1},a_{t+1})}] Bellman optimality equation v_*(s)=\mathbb{E}[r_{t+1} +\gamma max_\pi{v(s_{t+1})|s_t=s}] q_*(s,a)=\mathbb{E}[r_{t+1} +\gamma max_{a_{t+1}}{q(s_{t+1},a_{t+1})|s_t=s,a_t=a}]四、Monte-Carlo与Time Difference MC 方差较大，需要较深的探索获取回报 TD 方差较小，偏差较大，可设定探索深度(1-step, n-step), Q-Learning, SARSA都属于TD 【参考】https://zhuanlan.zhihu.com/p/25239682 Monte-Carlo method适用于“情节式任务”（情节任务序列有终点，与“情节式任务”相对应的是“连续型任务”）。$Q(s,a)$就是整个序列的期望回报。MC增量更新中的Monte-Carlo error ($R-Q(s_t,a_t)$)： Q(s_t,a_t)\Leftarrow Q(s_t,a_t) + \alpha(R-Q(s_t,a_t))TD（Time Difference） method，是MC和DP 方法的一个结合。相比MC方法，TD除了能够适用于连续任务外，和MC的差异从下图可以清楚看到。MC需要回退整个序列更新Q值，而TD只需要回退1步或n步更新Q值。因为MC需要等待序列结束才能训练，而TD没有这个限制，因此TD收敛速度明显比MC快，目前的主要算法都是基于TD。下图是TD和MC的回退图，很显然MC回退的更深。 1-step TD error: ($r_{t+1}+\gamma Q(s_{t+1}a_{t+1}-Q(s_t,a_t)​$)： Q(s_t,a_t) \Leftarrow Q(s_t,a_t)+\alpha(r_{t+1}+\gamma Q(s_{t+1}a_{t+1}-Q(s_t,a_t))n-steps TD error： TD(λ) error: 事实上，MC error可以视为一个情节任务的max-step TD error。另外，一般来说，在TD error中，n越大，用到的真实回报信息更多，收敛也会越快。]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MPC控制笔记(一)]]></title>
    <url>%2Fpost%2F10696.html</url>
    <content type="text"><![CDATA[笔记参考1：Understanding Model Predictive Control(Youtube 带自动生成字幕)笔记参考2：Understanding Model Predictive Control(B站 生肉) 一、什么是MPC模型预测控制MPC(Model Predict Control)是一种反馈控制(feedback control)算法, 使用模型来预测过程的未来输出。 举例： [场景] 车道保持 [已知模型] 车辆模型，比如速度控制， 转向控制对应的偏航量 [预测] 根据已知模型和所选的控制策略(action)，进行轨迹预测 [优化] 通过优化控制策略，来尽可能的拟合预测的轨迹。 如下图所示为一个MIMO系统u1,u2输入与y1,y2输出相互影响。如果使用PID控制的话，每一个子系统单独设计一个PID控制器，两个相互影响的子系统没有任何的交联，使得系统难以设计，如果像图二一样设计一个较大的系统，则参数较多难以实现，而使用MPC控制器的话可以较好的解决两种问题，综合相互间的影响来设计参数。MPC控制 此外MPC控制还可以方便的支持各种约束条件，具备一定的预测能力(有点像前馈feedforward控制)。 二、MPC的特点综合上述，总结一下MPC的特点： 支持MIMO系统，便于构建输入输出间的相互影响参数 支持方便添加约束条件 具有预测能力、 需要较好的处理器和较大的内存，因为需要大量的在线优化，存储大量的变量 三、MPC参数选择选择一个好的参数不仅影响MPC控制的性能，而且还会影响到MPC每一个timestep内进行在线优化的计算复杂度。这里将会给出关于控制器采样周期、预测及控制范围(prediction and control)、约束及权重。 采样周期的选择采样周期过大，则系统反应过慢导致难以及时进行修正控制，而采样周期过小，则会导致系统产生大量的在线优化计算，给系统带来较大的开销。因而建议采样周期设计采用开环响应时间(10~90%上升时间)的十分之一或二十分之一： 预测范围(prediction horizon)的选择预测范围指的是一次优化后预测未来输出的时间步的个数。建议范围：在开环响应时间内采样20-30个样本的范围 控制范围(control horizon)的选择如下图 [k, k+m]范围为控制范围，之后的红色部分称为 held constant，其中控制范围是要通过优化器来进行优化的参数动作。 过小的控制范围，可能无法做到较好的控制，而较大的控制范围，比如与预测范围相等，则会导致只有前一部分的控制范围才会有较好的效果，而后一部分的控制范围则收效甚微，而且将带来大量的计算开销。 建议控制范围应该在预测范围的10~20%之间,最小值为2~3个timestep时间步 约束对于约束，一般分为Hard约束和Soft约束，Hard约束是不可违背必须遵守的，在控制系统中，输入输出都可能会有约束限制，但是在设计时不建议将输入输出都给予Hard约束，因为这两部的约束有可能是有重叠的，导致优化器会产生不可行解。建议输出采用较小容忍度的Soft约束，而输入的话建议输入和输入参数变化率二者之间不要同时为Hard约束，可以一个Hard一个Soft。 四、Linear MPC (Adaptive MPC 与 Gain-Scheduled MPC)Linear MPC适用于:对于非线性系统而言,需要在不同的operating point处进行线性化处理如下图。 Adaptive MPC在 Adaptive MPC中，当operating condition发生变化的时候，需要进行一次近似线性化计算，在每个时间步中，使用其近似线性模型来更新内部的平台模型(plant model，比如飞控模型，自行车模型等)。在 Adaptive MPC中，在不同的operating point条件下，其优化问题的结构保持不变，即状态数量，约束数量不会随着operating condition而改变。 Gain-Scheduled MPC在 Gain-Scheduled MPC中，在不同的operating point条件下，其优化问题的结构会发生变化，需要为每一个operating point构建一个MPC控制器，且相互之间独立，其状态数量约束数量也可能不同。在 Gain-Scheduled MPC模式下，需要设计调度算法来切换不同的MPC模型。 二者选型[Adaptive MPC] 当能够构建平台(如飞行器，自动车等)的runtime线性模型，且在不同的operating point下优化问题的结构不变。 [Gain-Scheduled MPC] 当能够构建平台(如飞行器，自动车等)的runtime线性模型，且在不同的operating point下优化问题的结构发生变化。 五、Non-Linear MPC (Adaptive MPC 与 Gain-Scheduled MPC)Non-Linear MPC适用于(相对强大，能够提供更准确的预测能力，与决策支持，但是非线性优化的计算开销较大)]]></content>
      <tags>
        <tag>MPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Generative Adversarial Imitation Learning(GAIL) 论文阅读笔记]]></title>
    <url>%2Fpost%2F21152.html</url>
    <content type="text"><![CDATA[GAIL优点相较于IRL，可以省略很多中间步骤，比如通过IRL来学习Reward系统，再通过Reward系统来进行RL学习policy，GAIL可以直接通过expert trajectory 来直接学习policy。 IRL假定cost function的集合为$C $, $\pi_E$为专家策略(一系列采集来的专家策略样本)。IRL的目标是maximum causal entropy IRL其中是策略π的γ-discounted causal entropy，对于每一个cost function $c \in C$都有对于专家策略的cost最小，而其他策略的cost都相对较大。式(1)中包含了一个RL过程，实现了cost function到可以最小化期望cost误差的高熵策略的映射：]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无外网情况下RPM方式安装MySQL5.6]]></title>
    <url>%2Fpost%2F20206.html</url>
    <content type="text"><![CDATA[RPM方式安装MySQL5.6a. 检查MySQL及相关RPM包，是否安装，如果有安装，则移除（rpm –e 名称）123[root@localhost ~]# rpm -qa | grep -i mysqlmysql-libs-5.1.66-2.el6_3.x86_64[root@localhost ~]# yum -y remove mysql-libs* b. 下载Linux对应的RPM包，如：CentOS6.4_64对应的RPM包，如下：这里给出我下载好的包，官网下载巨慢。。有可能还需要一个perl库的依赖，这里一并给出。链接: http://pan.baidu.com/s/1skFrEK9 密码: apza12345[root@localhost rpm]# lltotal 74364-rw-r--r--. 1 root root 18442536 Dec 11 20:19 MySQL-client-5.6.15-1.el6.x86_64.rpm-rw-r--r--. 1 root root 3340660 Dec 11 20:06 MySQL-devel-5.6.15-1.el6.x86_64.rpm-rw-r--r--. 1 root root 54360600 Dec 11 20:03 MySQL-server-5.6.15-1.el6.x86_64.rpm c. 安装MySQL(如有必要需要安装perl-libs-5.10.1-141.el6_7.1.x86_64)12345[root@localhost rpm]# rpm -ivh MySQL-server-5.6.15-1.el6.x86_64.rpm[root@localhost rpm]# rpm -ivh MySQL-devel-5.6.15-1.el6.x86_64.rpm[root@localhost rpm]# rpm -ivh MySQL-client-5.6.15-1.el6.x86_64.rpm#修改配置文件位置[root@localhost rpm]# cp /usr/share/mysql/my-default.cnf /etc/my.cnf d. 在my.cnf文件中的[mysqld]下设置这一行：datadir = /usr/local/mysql/var e. 初始化MySQL及设置密码12345678[root@localhost rpm]# /usr/bin/mysql_install_db[root@localhost rpm]# service mysql start[root@localhost rpm]# cat /root/.mysql_secret #查看root账号密码,若无此文件可以直接使用无密码登录，若无密码登录失败，则需要在my.cnf文件中加入skip-grant-tables，并重启mysql服务# The random password set for the root user at Wed Dec 11 23:32:50 2013 (local time): qKTaFZnl[root@localhost ~]# mysql -uroot –pqKTaFZnlmysql&gt; SET PASSWORD = PASSWORD('123456'); #设置密码为123456mysql&gt; exit[root@localhost ~]# mysql -uroot -p123456 f. 允许远程登陆1234567891011121314mysql&gt; use mysql;mysql&gt; select host,user,password from user;+-----------------------+------+-------------------------------------------+| host | user | password |+-----------------------+------+-------------------------------------------+| localhost | root | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 || localhost.localdomain | root | *1237E2CE819C427B0D8174456DD83C47480D37E8 || 127.0.0.1 | root | *1237E2CE819C427B0D8174456DD83C47480D37E8 || ::1 | root | *1237E2CE819C427B0D8174456DD83C47480D37E8 |+-----------------------+------+-------------------------------------------+mysql&gt; update user set password=password('123456') where user='root';mysql&gt; update user set host='%' where user='root' and host='localhost';mysql&gt; flush privileges;mysql&gt; exit g. 设置开机自启动123[root@localhost ~]# chkconfig mysql on[root@localhost ~]# chkconfig --list | grep mysqlmysql 0:off 1:off 2:on 3:on 4:on 5:on 6:off h.MySQL的默认安装位置1234/var/lib/mysql/ #数据库目录/usr/share/mysql #配置文件目录/usr/bin #相关命令目录/etc/init.d/mysql #启动脚本 i.修改字符集和数据存储路径配置/etc/my.cnf文件,修改数据存放路径、mysql.sock路径以及默认编码utf-8.123456789101112131415[client]password = 123456port = 3306default-character-set=utf8[mysqld]port = 3306character_set_server=utf8character_set_client=utf8collation-server=utf8_general_ci#(注意linux下mysql安装完后是默认：表名区分大小写，列名不区分大小写； 0：区分大小写，1：不区分大小写)lower_case_table_names=1#(设置最大连接数，默认为 151，MySQL服务器允许的最大连接数16384; )max_connections=1000[mysql]default-character-set = utf8 j. 查看字符集12show variables like '%collation%';show variables like '%char%';]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker给运行中的容器添加映射端口]]></title>
    <url>%2Fpost%2F46919.html</url>
    <content type="text"><![CDATA[声明​ 这篇文章选自[教程技巧] DOCKER 给运行中的容器添加映射端口 正文Docker 给运行中的容器添加映射端口方法1 获得容器IP 1$ docker inspect `container_name` | grep IPAddress 比如我的容器叫mysqlserver么就输入下列代码来获取该容器的ip地址 1$ docker inspect mysqlserver | grep IPAddress 执行完之后会发现我的mysqlserverdocker容器的ip地址为192.168.0.2 ​ iptables转发端口 比如我将容器的3306端口映射到主机的37221端口，那么ip对应就写入我的docker容器IP即可 1iptables -t nat -A DOCKER -p tcp --dport 37221 -j DNAT --to-destination 192.168.0.2:3306 Docker 给运行中的容器添加映射端口方法2 提交一个运行中的容器为镜像 1$ docker commit containerid foo/live 运行镜像并添加端口 1$ docker run -d -p 8000:80 foo/live /bin/bash ​]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Scala基于词法单元的解析器定制EBNF范式文法解析]]></title>
    <url>%2Fpost%2F33864.html</url>
    <content type="text"><![CDATA[前言近期在做Oracle迁移到Spark平台的项目上遇到了一些平台公式翻译为SparkSQL(on Hive)的需求，而Spark采用亲妈语言Scala进行开发。分析过大概需求过后，拟使用编译原理中的EBNF范式模式，进行基于词法的文法解析。于是拟采用传统的正则词法解析到EBNF文法解析的套路来实现,直到发现了StandardTokenParsers这个Scala基于词法单元的解析器类。 平台公式及翻译后的SparkSQL平台公式的样子如下所示：1if (XX1_m001[D003]="邢おb7肮α䵵薇" || XX1_m001[H003]&lt;"2") &amp;&amp; XX1_m001[D005]!="wed" then XX1_m001[H022,COUNT] 这里面字段值”邢おb7肮α䵵薇”为这个的目的是为了测试各种字符集是否都能匹配满足。那么对应的SparkSQL应该是这个样子的,由于是使用的Hive on Spark，因而长得跟Oracle的SQL语句差不多：1SELECT COUNT(H022) FROM XX1_m001 WHERE (XX1_m001.D003='邢おb7肮α䵵薇' OR XX1_m001.H003&lt;'2') AND XX1_m001.D005&lt;'wed' 总体而言比较简单，因为我只是想在这里做一个Demo。 平台公式的EBNF范式及词法解析设计1234expr-condition ::= tableName "[" valueName "]" comparator Conditionexpr-front ::= expr-condition (("&amp;&amp;"|"||")expr-front)*expr-back ::= tableName "[" valueName "," operator "]"expr ::= "if" expr-front "then" expr-back 其中词法定义如下1234operator =&gt; [SUM,COUNT]tableName,valueName =&gt;ident #ident为关键字comparator =&gt; ["=","&gt;=","&lt;=","&gt;","&lt;","!="]Condition =&gt; stringLit #stringLit为字符串常量 使用Scala基于词法单元的解析器解析上述EBNF文法Scala基于词法单元的解析器是需要继承StandardTokenParsers这个类的，该类提供了很方便的解析函数，以及词法集合。我们可以通过使用lexical.delimiters列表来存放在文法翻译器执行过程中遇到的分隔符，使用lexical.reserved列表来存放执行过程中的关键字。比如，我们参照平台公式，看到&quot;=&quot;,&quot;&gt;=&quot;,&quot;&lt;=&quot;,&quot;&gt;&quot;,&quot;&lt;&quot;,&quot;!=&quot;,&quot;&amp;&amp;&quot;,&quot;||&quot;,&quot;[&quot;,&quot;]&quot;,&quot;,&quot;,&quot;(&quot;,&quot;)&quot;这些都是分隔符，其实我们也可以把&quot;=&quot;,&quot;&gt;=&quot;,&quot;&lt;=&quot;,&quot;&gt;&quot;,&quot;&lt;&quot;,&quot;!=&quot;,&quot;&amp;&amp;&quot;,&quot;||&quot;当做是关键字，但是我习惯上将带有英文字母的单词作为关键字处理。因而，这里的关键字集合便是&quot;if&quot;,&quot;then&quot;,&quot;SUM&quot;,&quot;COUNT&quot;这些。表现在代码中是酱紫的：12lexical.delimiters += ("=","&gt;=","&lt;=","&gt;","&lt;","!=","&amp;&amp;","||","[","]",",","(",")")lexical.reserved += ("if","then","SUM","COUNT") 是不是so easy~。我们再来看一下如何使用基于词法单元的解析器解析前面我们设计的EBNF文法呢。我在这里先上代码：12345678910111213141516171819202122232425262728293031323334353637383940class ExprParsre extends StandardTokenParsers&#123; lexical.delimiters += ("=","&gt;=","&lt;=","&gt;","&lt;","!=","&amp;&amp;","||","[","]",",","(",")") lexical.reserved += ("if","then","SUM","COUNT") def expr: Parser[String] = "if" ~ expr_front ~ "then" ~ expr_back ^^&#123; case "if" ~ exp1 ~ "then" ~ exp2 =&gt; exp2 + " WHERE " +exp1 &#125; def expr_priority: Parser[String] = opt("(") ~ expr_condition ~ opt(")") ^^&#123; case Some("(") ~ conditions ~ Some(")") =&gt; "(" + conditions +")" case Some("(") ~ conditions ~ None =&gt; "(" + conditions case None ~ conditions ~ Some(")") =&gt; conditions +")" case None ~ conditions ~ None =&gt; conditions &#125; def expr_condition: Parser[String] = ident ~ "[" ~ ident ~ "]" ~ ("="|"&gt;="|"&lt;="|"&gt;"|"&lt;"|"!=") ~ stringLit ^^&#123; case ident1~"["~ident2~"]"~"="~stringList =&gt; ident1 + "." + ident2 +"='" + stringList +"'" case ident1~"["~ident2~"]"~"&gt;="~stringList =&gt; ident1 + "." + ident2 +"&gt;='" + stringList +"'" case ident1~"["~ident2~"]"~"&lt;="~stringList =&gt; ident1 + "." + ident2 +"&lt;='" + stringList +"'" case ident1~"["~ident2~"]"~"&gt;"~stringList =&gt; ident1 + "." + ident2 +"&gt;'" + stringList +"'" case ident1~"["~ident2~"]"~"&lt;"~stringList =&gt; ident1 + "." + ident2 +"&lt;'" + stringList +"'" case ident1~"["~ident2~"]"~"!="~stringList =&gt; ident1 + "." + ident2 +"!='" + stringList +"'" &#125; def comparator: Parser[String] = ("&amp;&amp;"|"||") ^^&#123; case "&amp;&amp;" =&gt; " AND " case "||" =&gt; " OR " &#125; def expr_front: Parser[String] = expr_priority ~ rep(comparator ~ expr_priority) ^^&#123; case exp1 ~ exp2 =&gt; exp1 + exp2.map(x =&gt;&#123;x._1 + " " + x._2&#125;).mkString(" ") &#125; def expr_back: Parser[String] = ident ~ "[" ~ ident ~ "," ~ ("SUM"|"COUNT") ~ "]" ^^ &#123; case ident1~"["~ident2~","~"COUNT"~"]" =&gt; "SELECT COUNT("+ ident2.toString() +") FROM " + ident1.toString() case ident1~"["~ident2~","~"SUM"~"]" =&gt; "SELECT SUM("+ ident2.toString() +") FROM " + ident1.toString() &#125; def parserAll[T]( p : Parser[T], input :String) = &#123; phrase(p)( new lexical.Scanner(input)) &#125;&#125;]]></content>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内存占用过高？非也]]></title>
    <url>%2Fpost%2F24621.html</url>
    <content type="text"><![CDATA[前言 今天在我的RPi2上测试GPIO程序，忽然发现机器超卡，重启之后依然如此。于是我top了一下发现了一个问题就是内存爆满！！可我还啥都没干呢这是咋了？于是我呵呵地开始查资料，终于找到了问题所在。 正文 先来在阿里的ECS上top一下感受内存爆满的感觉，终端输入top 1#top 结合操作系统，计组等课程，以及多年以来windows培养给我的直觉，认为0.96G（1016272K）的总内存，使用了0.84G(880960K)的内存，使用率高达88%。然而我还啥都没干，怎么会这样呢？仔细查看还会发现后面有一个buffers，Swap后面还有一个Cached Mem。现在我们用free来观察下 1#free -m 虽然Mem显示了0.9G左右的used，但是-/+ buffers/cache(减去buffers和cache的结果)可以看到，当前进程实际占用内存是0.24G(256348K)，而可用空闲（free）内存为0.72G(759924K)。可以这么理解：在linux的内存分配机制中，优先使用物理内存，当物理内存还有空闲时（还够用），不会释放其占用内存，就算占用内存的程序已经被关闭了，该程序所占用的内存用来做缓存使用，对于开启过的程序、或是读取刚存取过得数据会比较快。 如上面的例子：共1G的内存，0.9G被占用，但是buffer和cached mem部分作为缓存，可以使用命中率的方式提高使用效率，而且这部分缓存是根据指令随时可以释放的，我们可以认为这部分内存没有实际被使用，也可以认为它是空闲的。因此查看目前进程正在实际被使用的内存，是used-(buffers+cache)，也可以认为如果swap没有大量使用，mem还是够用的，只有mem被当前进程实际占用完（没有了buffers和cache），才会使用到swap的。 再举个栗子： 这个是我在RPi一群看到的一个群友发的探针监测截图 观察内存使用状况一栏，发现物理内存功925.89M，已用911.74M，Cache化的内存是676.46M，Buffers为61.3M，现在用上述公式： 1真实的内存使用=used-(buffers+cache) 带入： 12真实使用内存 = 911.74-676.46-61.3 = 173.98与第三行的灰条的173.98相符 总结 很高兴对于linux的内存分配有了新的认识 多谢一群的 粵-打雜小白-503 Service Unavailable 的技术支持 多谢Licess’s Blog的精彩分析]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在raspbian-jessie上搭建nat123自启动]]></title>
    <url>%2Fpost%2F34931.html</url>
    <content type="text"><![CDATA[前言什么是nat123? 现在我们的树莓派都是在路由器内网里面的，需要使用nat123来实现外网映射(类似花生壳)，但是nat123免费好用，这个原理在计算机网络中叫做隧道或者叫穿透。那么本文主要讲述如何在树莓派上配置nat123。 必要环境 ​ 现在本文所用的平台是树莓派2代b+，其实那个版本的RPi都OK，主要是raspbian-jessie的系统，不过貌似是raspbian的系统都适合使用，这里主要是nat123的环境必须配置好。 安装好mono环境 安装好nat123客户端 本文中我的nat123客户端安装在了官网所指示的/mnt 目录下，如图。 正文1.安装nat123客户端 首先在这里还是要给出官网所给的安装方法linux下安装nat123客户端，但是按照官网所述的方法，我总是卡在mono的安装过程上，如果哪位读者能够用那种方法配置成功请您在底下mark我一下~~。下面我说一下配置过程。 安装mono ​ 这里可能由于是我的软件源出了问题，无论如何也不能按照官网的方式在我的树莓派上装mono环境，那么我只好采取mono源码编译的方式来安装。 ​ 简单说一下每个步骤，首先通过wget获取mono源码，如果没有wget的请手动执行sudo apt-get install wget进行安装，然后使用tar解压，然后cd进入解压文件夹，然后使用./configure --prefix=/usr/local配置编译安装路径，最后make编译，make install安装mono。 123456$ wget http://download.mono-project.com/sources/mono/mono-4.0.1.44.tar.bz2$ tar -xvf mono-4.0.1.44.tar.bz2$ cd mono-4.0.1$ ./configure --prefix=/usr/local$ make$ make install ​ 这样执行完成后输入mono -V出现版本信息就OK了，可以按照官网的说明继续执行。那么在这里我继续总结一下nat123的全部安装步骤。&lt;/br&gt; 安装nat123客户端(本文安装路径为/mnt) 123$ cd /mnt $ wget http://www.nat123.com/down/nat123linux.tar.gz $ tar -zxvf nat123linux.tar.gz 客户端启动 1234$ sudo apt-get install screen $ cd /mnt $ screen -S nat123 $ sudo mono nat123linux.sh ​ 这里需要注意的是，在执行screen -S nat123 语句时-S是大写的S，如提示没有screen，则执行sudo apt-get install screen安装screen后再执行screen。然后就是要特别注意mono那句话前面一定要加sudo，除非你是root用户，否则会报奇葩错误。如果一切顺利，你将看到下面的样子。 ​ 这里please enter your nat123 username(enter x to exit): 输入你的nat123用户名please enter your nat123 password(enter x to exit):输入你的nat123密码，吐槽坑点，密码竟然是明文。 ​ 如果你的用户名密码都正确，你会看到下面的界面(官网盗图)，按住Ctrl键，并依次先按A，再按D，退出当前窗口就OK了。 那么此时基础环境就算搭建完了，下面你需要的是一个nat123的端口映射配置。 2.配置nat123端口 首先你需要登录你的nat123官网账户 点我带你飞 然后在用户中心中选择端口映射添加 然后按照下图所示进行填写 ​ 这里说明一下，应用类型填写的是其他(非网站)，映射路线默认选择nat123，除非你有VIP专线，应用名称就随你咯。值得注意的是，这里的内网端口这样填写，由于我做映射的目的是能够在外网SSH到我的树莓派，所以需要将我的localhost上的22端口映射出去，因而这里我将内网端口设为22，内网地址设为localhost。 ​ 再举个栗子，现在我的树莓派上有一个运行在localhost的5000端口上的flask服务器(一个python框架)程序，那么我想在外网请求这个服务器，那么我们就将内网端口设为5000，内网地址设为localhost。 ​ 然后其他的填写默认就行，如果像做域名解析的，请按照官网的自主域名到万网上去解析，这里不再多言~。 点击确认保存 ​ 那么从上图可以看到现在我有两个端口映射一个是flask的5000端口映射，一个是SSH的22端口映射。那么如果一切顺利的话(已经开了nat123客户端服务并且做好了端口映射)那么现在你就可以通过在SSH应用中输入你的外网域名，和外网端口连接到你的树莓派中去了，或者通过外网域名，外网端口访问你的服务器应用。 3.将树莓派上的nat123服务设为开机自启动或断网重连 ​ 其实到上面为止，已经达到了我们想要的外网访问内网服务器的效果了，那么现在我们还不满足，想让他只用一次配置就可以永久稳定的生效，那么我们就把它配置成开机自启动并支持断网重连。之前看了官网上的方法，发现并没卵用，然后在刷官方论坛的时候发现了一个解决方案(论坛15楼的办法)，虽然可能是因为版本老了的原因，直接用并不成功，但是给了我一个很好的思路。下面介绍一下我的方法。 首先sudo apt-get install expect安装expect支持 然后进入nat123安装目录(本文是/mnt)，新建一个脚本起名为expect.sh，执行这条命令sudo vim /mnt/expect.sh 然后将下列代码输入到这个脚本中去: ​ 这里需要注意的是username=&quot;&quot;“”里面输入你的nat123用户名mypwd=&quot;&quot;“”里面输入你的nat123账号密码，值得一提的是，请看\&quot;please enter your nat123 username(enter x to exit):\&quot; {和\&quot;please enter your nat123 password(enter x to exit):\&quot; {这两句话一定要和你执行了sudo mono nat123linux.sh之后的输入提示相一致，具体在哪呢请看代码下面的那张图片。 12345678910111213141516171819202122#!/bin/bashusername="你的nat123用户名"mypwd="你的nat123密码"cmdnat123="sudo mono /mnt/nat123linux.sh"expect -c"spawn $cmdnat123while &#123; 1 &#125; &#123; expect &#123; \"please enter your nat123 username(enter x to exit):\" &#123; send \"$username\r\"; &#125; \"please enter your nat123 password(enter x to exit):\" &#123; send \"$mypwd\r\"; &#125; eof &#123; send \"exit\r\"; &#125; &#125; sleep 5;&#125; 写好之后可以执行bash expect.sh语句来执行以下这个脚本，如果执行之后它带你来到了让你输入ctrl+AD退出的那个界面，就说明这个脚本写的成功了。 然后将脚本执行写入开机启动bash 打开rc.local写入开机执行命令。 1$ sudo vim /etc/rc.local 这里在exit(0)这句之前一行写上sudo bash /mnt/expect.sh就OK了 那么如果顺利的话重启树莓派等待30s左右时间，你就可以直接通过外网访问你的树莓派了~，然后你也可以把网线拔了重插，等个5s左右，发现也可以重连，那么就一切OK了。 总结此文第二遍写于2016年4月21日10:10:13，倒霉的typora昨晚上写到2点多变成乱码了。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的博客]]></title>
    <url>%2Fpost%2F57092.html</url>
    <content type="text"></content>
  </entry>
</search>
